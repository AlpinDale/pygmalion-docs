---
tags: [settings]
icon: dot
title: Context_Tokens
---
Number of tokens to submit to the model for sampling/that are used to generate the output.
Make sure this is higher than "Output Length".
Higher values increase the memory but it aslo increase the usage of VRAM/RAM.