---
order: 1000000
icon: telescope
title: Overview
---

PygmalionAI is a large language model, and as the name might imply, it needs a lot of computation power to run it. You will need a minimum of 16GB VRAM to run the model - without any optimizations, that is. Here's a list of all the GPUs that would work without any tweaks, out-of-the-box:

**Consumer-grade (Gaming) GPUs:**

GPU                 | Manufacturer      | VRAM { class="compact" }
---                 | ---               | ---
RTX 4090            | NVIDIA            | 24GB
RTX 4080            | NVIDIA            | 16GB
RTX 3090 Ti         | NVIDIA            | 24GB
RTX 3090            | NVIDIA            | 24GB
Titan RTX           | NVIDIA            | 24GB
Radeon RX 7900 XTX  | AMD               | 24GB
Radeon RX 6950 XT   | AMD               | 16GB
Radeon RX 6900 XT   | AMD               | 16GB
Radeon RX 7900 XT   | AMD               | 20GB
Radeon RX 6800 XT   | AMD               | 16GB
Radeon RX 6800      | AMD               | 16GB


!!!warning Your card isn't listed here?
If you don't have any of these cards, but have still have 6GB or more VRAM, you can still run Pygmalion! (Provided you're using NVIDIA) Please refer to the [Quickstart page](https://docs.alpindale.dev/quickstart/).
!!!

Please continue to the next section.
