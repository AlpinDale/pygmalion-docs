[[{"i":"what-is-pygmalionai","l":"What is PygmalionAI?","p":["PygmalionAI is an open-source L arge L anguage M odel (LLM) based on EleutherAI's GPT-J 6B.","In simple terms, Pygmalion is an AI fine-tuned for chatting and Role-Playing purposes. The current actively supported Pygmalion AI model is the 6B (6 Billion Parameters) variant."]},{"i":"how-do-i-use-pygmalion","l":"How do I use Pygmalion?","p":["Language models, including Pygmalion, generally run on Graphics Processing Units (GPUs), since they need access to fast memory and processing power to output coherent text at an acceptable speed. Pygmalion is no different. You need a powerful GPU to run the model.","If you don't have a powerful enough GPU, there are luckily alternative solutions. Google's Colaboratory offers free GPUs for all users - though for a limited time. We have ready-made notebooks that you can run to access Pygmalion. You can also use Colab on your mobile phone.","These docs will attempt to explain all the possible methods for running the AI, and in a language that is easy to understand. We will start with Google Colab, as it's generally the easiest method."]}],[{"l":"Colab Notebooks","p":["Running Pygmalion - or any Large Language Model - requires a significant amount of VRAM. The current absolute minimum requirement is 10GB for a comfortable experience. Anything lower, and you would either be unable to use the model, or generations will be too slow to be enjoyable.","Google has generously offered free GPUs for in their Colaboratory. The Colab's free plan offers an NVIDIA T4 (16GB) GPU, which is more than enough to run the 6B Pygmalion Model. A TPU v2-8 is also available in the free plan, but availibility is low due to high demand."]},{"l":"Notebooks","p":["There are currently two backends to run the Pygmalion 6B model - KoboldAI and Text-Generation-WebUI by oobabooga.","TavernAI is a frontend that connects to KoboldAI and essentially facilitates a connection to Pygmalion via Kobold while offering a pleasant looking User Interface. TavernAI by itself doesn't run Pygmalion - therefore you do not need a powerful PC to run TavernAI. You cannot use TavernAI with oobabooga's Text-Gen-WebUI.","If you're on Mobile, use either oobabooga's TextGen or TavernAI.","Click here for the notebook link, and here for the guide.","\uD83D\uDCF1 Click here.","\uD83D\uDCBB Click here.","When you're done using Pygmalion, please terminate your Colab session! You'll waste your quota otherwise, and might find yourself unable to connect to a GPU backend the next time you login."]}],[{"l":"KoboldAI","p":["Each Colab notebook will greet you with a guide. For the sake of simplicity, visual guides will be included below. You can find the notebook here. Middle click or right-click and open in a new tab if you want to follow along with this guide!","Make sure you're signed in to your Google Account before you attempt running any of the notebooks.","Scroll down and select the highlighted options, and then run the cell:","You might be warned that the notebook is not authored by Google - you can ignore it and click on Run anyway.","You'll be prompted to give the notebook access to your Google Drive files. Click on Connect to Google Drive. This will open a pop-up browser window where you'll give Colab access to your Google Account. Select the account you wish to use, then scroll down and click on \"Allow\".","Wait for the notebook to finish running. This can take up to 5 or 10 minutes.","Once it's loaded, two URLs will appear. If you wish to use KoboldAI with Tavern, please copy the first URL. If you wish to use Kobold by itself, please click on the second URL.","You can start using Pygmalion if you clicked on the second link. If you want to use it with Tavern, please refer to the TavernAI guide included here."]}],[{"l":"Text Generation WebUI","p":["activate_character_bias: Lets you add a snippet of text that'll be put before every reply your bot generates - but keeps it hidden from you. In simple terms, if you add *yells* in the character bias section, your character will yell every line.","activate_sending_pictures: Allows you to send pictures to your bots.","activate_silero_text_to_speech: Use this option if you want TTS for your bots.","cai_chat: Will mimic the appearance of Character.AI's user interface.","chat_language: Pygmalion is a primarily English-only model - this feature simply runs yours and your bot's responses through a translation service.","Each Colab notebook will greet you with a guide. For the sake of simplicity, visual guides will be included below. You can find the notebook here. Middle click or right-click and open in a new tab if you want to follow along with this guide!","If you're on mobile, run this cell and keep the audio file playing:","load_in_8bit: Pygmalion 6B's weights are stored in Floating Point 16 bits, this will load them in Integer 8 bits instead - which cuts down on the computation power required. Use this so you can increase context size to the maximum.","Make sure you're signed in to your Google Account before you attempt running any of the notebooks.","model: Use this option to select which version of the Pygmalion model you want - original is the first version of the model, main is the current stable release (v3), dev is the latest beta release.","Once the model is loaded, you can find your URL here:","Run the second cell, and make sure the save_logs_to_google_drive option is checked. If you don't check this, your characters and chatlogs won't persist across sessions on the same account:","Scroll down to the third cell and finally run Pygmalion:","text_streaming: The generated text by the bot is displayed in real-time instead of waiting for the whole message to finish generating before showing it to you.","Wait for the cell to finish loading Pygmalion. This cell will not stop running until you terminate your Colab session or manually stop it.","Wait for the cell to finish running. You can find out whether it's finished by checking if the cell button is still spinning:","Wait for the checkpoint shards to be loaded. This should take a few minutes at most.","You can now start chatting with any bot you want. You can find bots in our unofficial Discord Server.","You might be warned that the notebook is not authored by Google - you can ignore it and click on Run anyway.","You'll be prompted to give the notebook access to your Google Drive files. Click on Connect to Google Drive. This will open a pop-up browser window where you'll give Colab access to your Google Account. Select the account you wish to use, then scroll down and click on \"Allow\"."]}],[{"l":"TavernAI","p":["Each Colab notebook will greet you with a guide. For the sake of simplicity, visual guides will be included below. You can find the notebook here. Middle click or right-click and open in a new tab if you want to follow along with this guide!","Make sure you're signed in to your Google Account before you attempt running any of the notebooks.","If you're on mobile, run this cell and keep the audio file playing:","You might be warned that the notebook is not authored by Google - you can ignore it and click on Run anyway.","Scroll down and run this cell to launch Pygmalion with Tavern:","Choose Pygmalion Dev in the Model drop-down menu if you want to try the latest beta release of the model.","You'll be prompted to give the notebook access to your Google Drive files. Click on Connect to Google Drive. This will open a pop-up browser window where you'll give Colab access to your Google Account. Select the account you wish to use, then scroll down and click on \"Allow\".","Wait around 5 minutes for TavernAI to finish loading. You can find the URL here at the end:","You can now start chatting with any character you wish! TavernAI offers community-created characters, but you can also add your own by clicking on the burger menu to the top-right corner of the screen, and then the +Import button in the Characters menu. Find more characters in the unofficial Discord server."]}],[{"l":"Overview","p":["16GB","20GB","24GB","AMD","Consumer-grade (Gaming) GPUs:","GPU","If you don't have any of these cards, but still have over 8GB of VRAM, chances are you can still run the model just fine. You just have to make sure your card supports CUDA (NVIDIA) or ROCm (AMD). We'll get to that later.","Manufacturer","NVIDIA","PygmalionAI is a Large Language Model, and as the name might imply, it needs a lot of computation power to run it. You need a minimum of 16GB VRAM to run the model -- without any optimizations, that is. Here's a list of all the GPUs that would work without any tweaks and out-of-the-box:","Radeon RX 6800","Radeon RX 6800 XT","Radeon RX 6900 XT","Radeon RX 6950 XT","Radeon RX 7900 XT","Radeon RX 7900 XTX","RTX 3090","RTX 3090 Ti","RTX 4080","RTX 4090","Titan RTX","VRAM"]}],[{"l":"Frequently Asked Questions"},{"i":"my-character-has-terrible-memory","l":"My character has terrible memory!","p":["This could be due to the limited context size. Pygmalion 6B has a maximum context size of 2048 tokens. This includes your character description, example messages, and all your chatlogs. The description and examples are placed at the top of the context memory - all your subsequent chat logs are placed beneath them. This means that if your character description + examples chats are 400 tokens, you'll only have 1648 tokens left for your messages. The bot will forgot everything past those 1648 tokens.","Character editors/creators such as TavernAI's will give you a token count for your character, but you can also use OpenAI's tokenizer service.","OpenAI Tokenizer"]},{"i":"my-characters-responses-are-too-short","l":"My character's responses are too short!","p":["The character will mimic the example chats and greeting message's style. Keep these in mind if you want to create a verbose character:","Descriptive and verbose greeting message and example chats.","Descriptive and verbose responses by the user (you!).","Re-generate the response until you see a satisfactory one.","Manually edit the character's response to make it more verbose."]},{"i":"my-character-is-generating-nonsense","l":"My character is generating nonsense!","p":["Your Temperature or Repetition Penalty settings are likely too high. The recommended range for Temperature (for chatbots) is between 0.5 to 0.9. The range for Repetition Penalty is between 1.1 to 1.2."]}]]