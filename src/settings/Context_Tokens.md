---
tags: [settings]
icon: dot
title: Context Tokens
order: 1000000000
---
Number of tokens to submit to the model for sampling/that are used to generate the output.
Make sure this is higher than "Output Length".
Higher values increase the memory but it aslo increase the usage of VRAM/RAM.